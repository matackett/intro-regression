<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>6.4 Matrix Form of Linear Regression | Intro to Regression Analysis</title>
  <meta name="description" content="This document contains lab assignments and other materials for an intermediate-level regression course.">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="6.4 Matrix Form of Linear Regression | Intro to Regression Analysis" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This document contains lab assignments and other materials for an intermediate-level regression course." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="6.4 Matrix Form of Linear Regression | Intro to Regression Analysis" />
  
  <meta name="twitter:description" content="This document contains lab assignments and other materials for an intermediate-level regression course." />
  

<meta name="author" content="Maria Tackett">


<meta name="date" content="2019-05-14">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="6-3-analyzing-wages.html">
<link rel="next" href="6-5-log-transformations-in-linear-regression.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Broadening Your Statistical Horizons</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Beginning of the Book</a></li>
<li class="chapter" data-level="2" data-path="2-intro.html"><a href="2-intro.html"><i class="fa fa-check"></i><b>2</b> Introduction</a></li>
<li class="chapter" data-level="3" data-path="3-getstarted.html"><a href="3-getstarted.html"><i class="fa fa-check"></i><b>3</b> Getting Started</a></li>
<li class="chapter" data-level="4" data-path="4-slr.html"><a href="4-slr.html"><i class="fa fa-check"></i><b>4</b> Simple Linear Regression</a><ul>
<li class="chapter" data-level="4.1" data-path="4-1-computing-college-admissions.html"><a href="4-1-computing-college-admissions.html"><i class="fa fa-check"></i><b>4.1</b> Computing: College Admissions</a><ul>
<li class="chapter" data-level="4.1.1" data-path="4-1-computing-college-admissions.html"><a href="4-1-computing-college-admissions.html#packages"><i class="fa fa-check"></i><b>4.1.1</b> Packages</a></li>
<li class="chapter" data-level="4.1.2" data-path="4-1-computing-college-admissions.html"><a href="4-1-computing-college-admissions.html#data"><i class="fa fa-check"></i><b>4.1.2</b> Data</a></li>
<li class="chapter" data-level="4.1.3" data-path="4-1-computing-college-admissions.html"><a href="4-1-computing-college-admissions.html#exercises"><i class="fa fa-check"></i><b>4.1.3</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="4-2-in-class-exercise-advertising-analysis.html"><a href="4-2-in-class-exercise-advertising-analysis.html"><i class="fa fa-check"></i><b>4.2</b> In-Class Exercise: Advertising Analysis</a><ul>
<li class="chapter" data-level="4.2.1" data-path="4-2-in-class-exercise-advertising-analysis.html"><a href="4-2-in-class-exercise-advertising-analysis.html#data-and-packages"><i class="fa fa-check"></i><b>4.2.1</b> Data and packages</a></li>
<li class="chapter" data-level="4.2.2" data-path="4-2-in-class-exercise-advertising-analysis.html"><a href="4-2-in-class-exercise-advertising-analysis.html#analysis"><i class="fa fa-check"></i><b>4.2.2</b> Analysis</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="4-3-in-class-exercise-beer-data-analysis.html"><a href="4-3-in-class-exercise-beer-data-analysis.html"><i class="fa fa-check"></i><b>4.3</b> In-Class Exercise: Beer Data Analysis</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="5-anova.html"><a href="5-anova.html"><i class="fa fa-check"></i><b>5</b> Analysis of Variance</a><ul>
<li class="chapter" data-level="5.1" data-path="5-anova.html"><a href="5-anova.html#anova"><i class="fa fa-check"></i><b>5.1</b> ANOVA</a><ul>
<li class="chapter" data-level="5.1.1" data-path="5-1-anova.html"><a href="5-1-anova.html"><i class="fa fa-check"></i><b>5.1.1</b> Packages</a></li>
<li class="chapter" data-level="5.1.2" data-path="5-1-anova.html"><a href="5-1-anova.html#data-1"><i class="fa fa-check"></i><b>5.1.2</b> Data</a></li>
<li class="chapter" data-level="5.1.3" data-path="5-1-anova.html"><a href="5-1-anova.html#exercises-1"><i class="fa fa-check"></i><b>5.1.3</b> Exercises</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="6-mlr.html"><a href="6-mlr.html"><i class="fa fa-check"></i><b>6</b> Multiple Linear Regression</a><ul>
<li class="chapter" data-level="6.1" data-path="6-1-multiple-linear-regression.html"><a href="6-1-multiple-linear-regression.html"><i class="fa fa-check"></i><b>6.1</b> Multiple Linear Regression</a><ul>
<li class="chapter" data-level="6.1.1" data-path="6-1-multiple-linear-regression.html"><a href="6-1-multiple-linear-regression.html#packages-2"><i class="fa fa-check"></i><b>6.1.1</b> Packages</a></li>
<li class="chapter" data-level="6.1.2" data-path="6-1-multiple-linear-regression.html"><a href="6-1-multiple-linear-regression.html#data-2"><i class="fa fa-check"></i><b>6.1.2</b> Data</a></li>
<li class="chapter" data-level="6.1.3" data-path="6-1-multiple-linear-regression.html"><a href="6-1-multiple-linear-regression.html#exercises-2"><i class="fa fa-check"></i><b>6.1.3</b> Exercises</a></li>
<li class="chapter" data-level="6.1.4" data-path="6-1-multiple-linear-regression.html"><a href="6-1-multiple-linear-regression.html#acknowledgement"><i class="fa fa-check"></i><b>6.1.4</b> Acknowledgement</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="6-2-data-wrangling-multiple-linear-regression.html"><a href="6-2-data-wrangling-multiple-linear-regression.html"><i class="fa fa-check"></i><b>6.2</b> Data Wrangling &amp; Multiple Linear Regression</a><ul>
<li class="chapter" data-level="6.2.1" data-path="6-2-data-wrangling-multiple-linear-regression.html"><a href="6-2-data-wrangling-multiple-linear-regression.html#packages-3"><i class="fa fa-check"></i><b>6.2.1</b> Packages</a></li>
<li class="chapter" data-level="6.2.2" data-path="6-2-data-wrangling-multiple-linear-regression.html"><a href="6-2-data-wrangling-multiple-linear-regression.html#data-3"><i class="fa fa-check"></i><b>6.2.2</b> Data</a></li>
<li class="chapter" data-level="6.2.3" data-path="6-2-data-wrangling-multiple-linear-regression.html"><a href="6-2-data-wrangling-multiple-linear-regression.html#exercises-3"><i class="fa fa-check"></i><b>6.2.3</b> Exercises</a></li>
<li class="chapter" data-level="6.2.4" data-path="6-2-data-wrangling-multiple-linear-regression.html"><a href="6-2-data-wrangling-multiple-linear-regression.html#acknowledgement-1"><i class="fa fa-check"></i><b>6.2.4</b> Acknowledgement</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="6-3-analyzing-wages.html"><a href="6-3-analyzing-wages.html"><i class="fa fa-check"></i><b>6.3</b> Analyzing Wages</a><ul>
<li class="chapter" data-level="6.3.1" data-path="6-3-analyzing-wages.html"><a href="6-3-analyzing-wages.html#initial-model"><i class="fa fa-check"></i><b>6.3.1</b> Initial model</a></li>
<li class="chapter" data-level="6.3.2" data-path="6-3-analyzing-wages.html"><a href="6-3-analyzing-wages.html#model-with-mean-centered-variables"><i class="fa fa-check"></i><b>6.3.2</b> Model with mean-centered variables</a></li>
<li class="chapter" data-level="6.3.3" data-path="6-3-analyzing-wages.html"><a href="6-3-analyzing-wages.html#model-with-indicator-variables"><i class="fa fa-check"></i><b>6.3.3</b> Model with indicator variables</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="6-4-matrix-form-of-linear-regression.html"><a href="6-4-matrix-form-of-linear-regression.html"><i class="fa fa-check"></i><b>6.4</b> Matrix Form of Linear Regression</a><ul>
<li class="chapter" data-level="6.4.1" data-path="6-4-matrix-form-of-linear-regression.html"><a href="6-4-matrix-form-of-linear-regression.html#introduction"><i class="fa fa-check"></i><b>6.4.1</b> Introduction</a></li>
<li class="chapter" data-level="6.4.2" data-path="6-4-matrix-form-of-linear-regression.html"><a href="6-4-matrix-form-of-linear-regression.html#matrix-form-for-the-regression-model"><i class="fa fa-check"></i><b>6.4.2</b> Matrix Form for the Regression Model</a></li>
<li class="chapter" data-level="6.4.3" data-path="6-4-matrix-form-of-linear-regression.html"><a href="6-4-matrix-form-of-linear-regression.html#estimating-the-coefficients"><i class="fa fa-check"></i><b>6.4.3</b> Estimating the Coefficients</a></li>
<li class="chapter" data-level="6.4.4" data-path="6-4-matrix-form-of-linear-regression.html"><a href="6-4-matrix-form-of-linear-regression.html#variance-covariance-matrix-of-the-coefficients"><i class="fa fa-check"></i><b>6.4.4</b> Variance-covariance matrix of the coefficients</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="6-5-log-transformations-in-linear-regression.html"><a href="6-5-log-transformations-in-linear-regression.html"><i class="fa fa-check"></i><b>6.5</b> Log Transformations in Linear Regression</a><ul>
<li class="chapter" data-level="6.5.1" data-path="6-5-log-transformations-in-linear-regression.html"><a href="6-5-log-transformations-in-linear-regression.html#log-transformation-on-the-response-variable"><i class="fa fa-check"></i><b>6.5.1</b> Log-transformation on the response variable</a></li>
<li class="chapter" data-level="6.5.2" data-path="6-5-log-transformations-in-linear-regression.html"><a href="6-5-log-transformations-in-linear-regression.html#log-transformation-on-the-predictor-variable"><i class="fa fa-check"></i><b>6.5.2</b> Log-transformation on the predictor variable</a></li>
<li class="chapter" data-level="6.5.3" data-path="6-5-log-transformations-in-linear-regression.html"><a href="6-5-log-transformations-in-linear-regression.html#log-transformation-on-the-the-response-and-predictor-variable"><i class="fa fa-check"></i><b>6.5.3</b> Log-transformation on the the response and predictor variable</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="6-6-details-about-model-diagnostics.html"><a href="6-6-details-about-model-diagnostics.html"><i class="fa fa-check"></i><b>6.6</b> Details about Model Diagnostics</a><ul>
<li class="chapter" data-level="6.6.1" data-path="6-6-details-about-model-diagnostics.html"><a href="6-6-details-about-model-diagnostics.html#introduction-1"><i class="fa fa-check"></i><b>6.6.1</b> Introduction</a></li>
<li class="chapter" data-level="6.6.2" data-path="6-6-details-about-model-diagnostics.html"><a href="6-6-details-about-model-diagnostics.html#matrix-form-for-the-regression-model-1"><i class="fa fa-check"></i><b>6.6.2</b> Matrix Form for the Regression Model</a></li>
<li class="chapter" data-level="6.6.3" data-path="6-6-details-about-model-diagnostics.html"><a href="6-6-details-about-model-diagnostics.html#hat-matrix-leverage"><i class="fa fa-check"></i><b>6.6.3</b> Hat Matrix &amp; Leverage</a></li>
<li class="chapter" data-level="6.6.4" data-path="6-6-details-about-model-diagnostics.html"><a href="6-6-details-about-model-diagnostics.html#standardized-residuals"><i class="fa fa-check"></i><b>6.6.4</b> Standardized Residuals</a></li>
<li class="chapter" data-level="6.6.5" data-path="6-6-details-about-model-diagnostics.html"><a href="6-6-details-about-model-diagnostics.html#cooks-distance"><i class="fa fa-check"></i><b>6.6.5</b> Cook’s Distance</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="7-select.html"><a href="7-select.html"><i class="fa fa-check"></i><b>7</b> Model Selection</a><ul>
<li class="chapter" data-level="7.1" data-path="7-1-model-selection.html"><a href="7-1-model-selection.html"><i class="fa fa-check"></i><b>7.1</b> Model Selection</a><ul>
<li class="chapter" data-level="7.1.1" data-path="7-1-model-selection.html"><a href="7-1-model-selection.html#packages-4"><i class="fa fa-check"></i><b>7.1.1</b> Packages</a></li>
<li class="chapter" data-level="7.1.2" data-path="7-1-model-selection.html"><a href="7-1-model-selection.html#data-4"><i class="fa fa-check"></i><b>7.1.2</b> Data</a></li>
<li class="chapter" data-level="7.1.3" data-path="7-1-model-selection.html"><a href="7-1-model-selection.html#exercises-4"><i class="fa fa-check"></i><b>7.1.3</b> Exercises</a></li>
<li class="chapter" data-level="7.1.4" data-path="7-1-model-selection.html"><a href="7-1-model-selection.html#acknowledgements"><i class="fa fa-check"></i><b>7.1.4</b> Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="7-2-model-selection-1.html"><a href="7-2-model-selection-1.html"><i class="fa fa-check"></i><b>7.2</b> Model Selection</a><ul>
<li class="chapter" data-level="7.2.1" data-path="7-2-model-selection-1.html"><a href="7-2-model-selection-1.html#backward-selection-manually"><i class="fa fa-check"></i><b>7.2.1</b> Backward selection “manually”</a></li>
<li class="chapter" data-level="7.2.2" data-path="7-2-model-selection-1.html"><a href="7-2-model-selection-1.html#backward-selection-using-regsubsets"><i class="fa fa-check"></i><b>7.2.2</b> Backward selection using regsubsets</a></li>
<li class="chapter" data-level="7.2.3" data-path="7-2-model-selection-1.html"><a href="7-2-model-selection-1.html#changing-selection-criteria"><i class="fa fa-check"></i><b>7.2.3</b> Changing selection criteria</a></li>
<li class="chapter" data-level="7.2.4" data-path="7-2-model-selection-1.html"><a href="7-2-model-selection-1.html#different-selection-procedure"><i class="fa fa-check"></i><b>7.2.4</b> Different selection procedure</a></li>
<li class="chapter" data-level="7.2.5" data-path="7-2-model-selection-1.html"><a href="7-2-model-selection-1.html#choosing-a-final-model"><i class="fa fa-check"></i><b>7.2.5</b> Choosing a final model</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="7-3-model-selection-criteria-aic-bic.html"><a href="7-3-model-selection-criteria-aic-bic.html"><i class="fa fa-check"></i><b>7.3</b> Model Selection Criteria: AIC &amp; BIC</a><ul>
<li class="chapter" data-level="7.3.1" data-path="7-3-model-selection-criteria-aic-bic.html"><a href="7-3-model-selection-criteria-aic-bic.html#maximum-likelihood-estimation-of-boldsymbolbeta-and-sigma"><i class="fa fa-check"></i><b>7.3.1</b> Maximum Likelihood Estimation of <span class="math inline">\(\boldsymbol{\beta}\)</span> and <span class="math inline">\(\sigma\)</span></a></li>
<li class="chapter" data-level="7.3.2" data-path="7-3-model-selection-criteria-aic-bic.html"><a href="7-3-model-selection-criteria-aic-bic.html#aic"><i class="fa fa-check"></i><b>7.3.2</b> AIC</a></li>
<li class="chapter" data-level="7.3.3" data-path="7-3-model-selection-criteria-aic-bic.html"><a href="7-3-model-selection-criteria-aic-bic.html#bic"><i class="fa fa-check"></i><b>7.3.3</b> BIC</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="8-logistic.html"><a href="8-logistic.html"><i class="fa fa-check"></i><b>8</b> Logistic Regression</a><ul>
<li class="chapter" data-level="8.1" data-path="8-1-logistic-regression.html"><a href="8-1-logistic-regression.html"><i class="fa fa-check"></i><b>8.1</b> Logistic Regression</a><ul>
<li class="chapter" data-level="8.1.1" data-path="8-1-logistic-regression.html"><a href="8-1-logistic-regression.html#packages-5"><i class="fa fa-check"></i><b>8.1.1</b> Packages</a></li>
<li class="chapter" data-level="8.1.2" data-path="8-1-logistic-regression.html"><a href="8-1-logistic-regression.html#data-5"><i class="fa fa-check"></i><b>8.1.2</b> Data</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="8-2-exercises-5.html"><a href="8-2-exercises-5.html"><i class="fa fa-check"></i><b>8.2</b> Exercises</a><ul>
<li class="chapter" data-level="8.2.1" data-path="8-2-exercises-5.html"><a href="8-2-exercises-5.html#exploratory-data-analysis-1"><i class="fa fa-check"></i><b>8.2.1</b> Exploratory Data Analysis</a></li>
<li class="chapter" data-level="8.2.2" data-path="8-2-exercises-5.html"><a href="8-2-exercises-5.html#part-ii-logistic-regression-model"><i class="fa fa-check"></i><b>8.2.2</b> Part II: Logistic Regression Model</a></li>
<li class="chapter" data-level="8.2.3" data-path="8-2-exercises-5.html"><a href="8-2-exercises-5.html#part-iii-model-assessment"><i class="fa fa-check"></i><b>8.2.3</b> Part III: Model Assessment</a></li>
<li class="chapter" data-level="8.2.4" data-path="8-2-exercises-5.html"><a href="8-2-exercises-5.html#part-iv-prediction"><i class="fa fa-check"></i><b>8.2.4</b> Part IV: Prediction</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="8-3-logistic-regression-1.html"><a href="8-3-logistic-regression-1.html"><i class="fa fa-check"></i><b>8.3</b> Logistic Regression</a></li>
<li class="chapter" data-level="8.4" data-path="8-4-references.html"><a href="8-4-references.html"><i class="fa fa-check"></i><b>8.4</b> References</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="9-multinom-logistic.html"><a href="9-multinom-logistic.html"><i class="fa fa-check"></i><b>9</b> Multinomial Logistic Regression</a><ul>
<li class="chapter" data-level="9.1" data-path="9-1-multinomial-logistic-regression.html"><a href="9-1-multinomial-logistic-regression.html"><i class="fa fa-check"></i><b>9.1</b> Multinomial Logistic Regression</a><ul>
<li class="chapter" data-level="9.1.1" data-path="9-1-multinomial-logistic-regression.html"><a href="9-1-multinomial-logistic-regression.html#packages-6"><i class="fa fa-check"></i><b>9.1.1</b> Packages</a></li>
<li class="chapter" data-level="9.1.2" data-path="9-1-multinomial-logistic-regression.html"><a href="9-1-multinomial-logistic-regression.html#data-6"><i class="fa fa-check"></i><b>9.1.2</b> Data</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="9-2-exercises-6.html"><a href="9-2-exercises-6.html"><i class="fa fa-check"></i><b>9.2</b> Exercises</a><ul>
<li class="chapter" data-level="9.2.1" data-path="9-2-exercises-6.html"><a href="9-2-exercises-6.html#part-i-exploratory-data-analysis"><i class="fa fa-check"></i><b>9.2.1</b> Part I: Exploratory Data Analysis</a></li>
<li class="chapter" data-level="9.2.2" data-path="9-2-exercises-6.html"><a href="9-2-exercises-6.html#part-ii-multinomial-logistic-regression-model"><i class="fa fa-check"></i><b>9.2.2</b> Part II: Multinomial Logistic Regression Model</a></li>
<li class="chapter" data-level="9.2.3" data-path="9-2-exercises-6.html"><a href="9-2-exercises-6.html#part-iii-model-fit"><i class="fa fa-check"></i><b>9.2.3</b> Part III: Model Fit</a></li>
<li class="chapter" data-level="9.2.4" data-path="9-2-exercises-6.html"><a href="9-2-exercises-6.html#part-iv-using-the-model"><i class="fa fa-check"></i><b>9.2.4</b> Part IV: Using the Model</a></li>
<li class="chapter" data-level="9.2.5" data-path="9-2-exercises-6.html"><a href="9-2-exercises-6.html#acknowledgements-1"><i class="fa fa-check"></i><b>9.2.5</b> Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="9-3-multinomial-logistic-regression-1.html"><a href="9-3-multinomial-logistic-regression-1.html"><i class="fa fa-check"></i><b>9.3</b> Multinomial Logistic Regression</a><ul>
<li class="chapter" data-level="9.3.1" data-path="9-3-multinomial-logistic-regression-1.html"><a href="9-3-multinomial-logistic-regression-1.html#questions"><i class="fa fa-check"></i><b>9.3.1</b> Questions</a></li>
<li class="chapter" data-level="9.3.2" data-path="9-3-multinomial-logistic-regression-1.html"><a href="9-3-multinomial-logistic-regression-1.html#references-1"><i class="fa fa-check"></i><b>9.3.2</b> References</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="10-special.html"><a href="10-special.html"><i class="fa fa-check"></i><b>10</b> Special Topics</a><ul>
<li class="chapter" data-level="10.1" data-path="10-1-putting-it-all-together.html"><a href="10-1-putting-it-all-together.html"><i class="fa fa-check"></i><b>10.1</b> Putting It All Together</a><ul>
<li class="chapter" data-level="10.1.1" data-path="10-1-putting-it-all-together.html"><a href="10-1-putting-it-all-together.html#packages-7"><i class="fa fa-check"></i><b>10.1.1</b> Packages</a></li>
<li class="chapter" data-level="10.1.2" data-path="10-1-putting-it-all-together.html"><a href="10-1-putting-it-all-together.html#data-7"><i class="fa fa-check"></i><b>10.1.2</b> Data</a></li>
<li class="chapter" data-level="10.1.3" data-path="10-1-putting-it-all-together.html"><a href="10-1-putting-it-all-together.html#exercises-7"><i class="fa fa-check"></i><b>10.1.3</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="10-2-dealing-with-missing-data.html"><a href="10-2-dealing-with-missing-data.html"><i class="fa fa-check"></i><b>10.2</b> Dealing with Missing Data</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="11-data-sets.html"><a href="11-data-sets.html"><i class="fa fa-check"></i><b>11</b> Data Sets</a></li>
<li class="chapter" data-level="12" data-path="12-refs.html"><a href="12-refs.html"><i class="fa fa-check"></i><b>12</b> References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Intro to Regression Analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="matrix-form-of-linear-regression" class="section level2">
<h2><span class="header-section-number">6.4</span> Matrix Form of Linear Regression</h2>
<p>This document provides the details for the matrix form of multiple linear regression. We assume the reader has familiarity with some matrix alegbra. Please see Chapter 1 of <a href="https://www-bcf.usc.edu/~gareth/ISL/"><em>An Introduction to Statistical Learning</em></a> for a brief review of matrix algebra.</p>
<div id="introduction" class="section level3">
<h3><span class="header-section-number">6.4.1</span> Introduction</h3>
<p>Suppose we have <span class="math inline">\(n\)</span> observations. Let the <span class="math inline">\(i^{th}\)</span> be <span class="math inline">\((x_{i1}, \ldots, x_{ip}, y_i)\)</span>, such that <span class="math inline">\(x_{i1}, \ldots, x_{ip}\)</span> are the explanatory variables (predictors) and <span class="math inline">\(y_i\)</span> is the response variable. We assume the data can be modeled using the least-squares regression model, such that the mean response for a given combination of explanatory variables follows the form in ().</p>
<span class="math display">\[\begin{equation}
\label{basic_model}
y = \beta_0 + \beta_1 x_1 + \dots + \beta_p x_p 
\end{equation}\]</span>
<p>We can write the response for the <span class="math inline">\(i^{th}\)</span> observation as shown in ()</p>
<span class="math display">\[\begin{equation}
\label{ind_response}
y_i = \beta_0 + \beta_1 x_{i1} + \dots + \beta_p x_{ip} + \epsilon_i 
\end{equation}\]</span>
<p>such that <span class="math inline">\(\epsilon_i\)</span> is the amount <span class="math inline">\(y_i\)</span> deviates from <span class="math inline">\(\mu\{y|x_{i1}, \ldots, x_{ip}\}\)</span>, the mean response for a given combination of explanatory variables. We assume each <span class="math inline">\(\epsilon_i \sim N(0,\sigma^2)\)</span>, where <span class="math inline">\(\sigma^2\)</span> is a constant variance for the distribution of the response <span class="math inline">\(y\)</span> for any combination of explanatory variables <span class="math inline">\(x_1, \ldots, x_p\)</span>.</p>
</div>
<div id="matrix-form-for-the-regression-model" class="section level3">
<h3><span class="header-section-number">6.4.2</span> Matrix Form for the Regression Model</h3>
<p>We can represent the () and () using matrix notation. Let</p>
<span class="math display">\[\begin{equation}
\label{matrix notation}
\mathbf{Y} = \begin{bmatrix}y_1 \\ y_2 \\ \vdots \\y_n\end{bmatrix} 
\hspace{15mm}
\mathbf{X} = \begin{bmatrix}x_{11} &amp; x_{12} &amp; \dots &amp; x_{1p} \\
x_{21} &amp; x_{22} &amp; \dots &amp; x_{2p} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots\\
x_{n1} &amp; x_{n2} &amp; \dots &amp; x_{np} \end{bmatrix}
\hspace{15mm}
\boldsymbol{\beta}= \begin{bmatrix}\beta_0 \\ \beta_1 \\ \vdots \\ \beta_p \end{bmatrix} 
\hspace{15mm}
\boldsymbol{\epsilon}= \begin{bmatrix}\epsilon_1 \\ \epsilon_2 \\ \vdots \\ \epsilon_n \end{bmatrix}
\end{equation}\]</span>
<p>Thus,</p>
<p><span class="math display">\[\mathbf{Y} = \mathbf{X}\boldsymbol{\beta} + \mathbf{\epsilon}\]</span></p>
<p>Therefore the estimated response for a given combination of explanatory variables and the associated residuals can be written as</p>
<span class="math display">\[\begin{equation}
\label{matrix_mean}
\hat{\mathbf{Y}} = \mathbf{X}\hat{\boldsymbol{\beta}} \hspace{10mm} \mathbf{e} = \mathbf{Y} - \mathbf{X}\hat{\boldsymbol{\beta}}
\end{equation}\]</span>
</div>
<div id="estimating-the-coefficients" class="section level3">
<h3><span class="header-section-number">6.4.3</span> Estimating the Coefficients</h3>
<p>The least-squares model is the one that minimizes the sum of the squared residuals. Therefore, we want to find the coefficients, <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span> that minimizes</p>
<span class="math display">\[\begin{equation}
\label{sum_sq_resid}
\sum\limits_{i=1}^{n} e_{i}^2 = \mathbf{e}^T\mathbf{e} = (\mathbf{Y} - \mathbf{X}\hat{\boldsymbol{\beta}})^T(\mathbf{Y} - \mathbf{X}\hat{\boldsymbol{\beta}})
\end{equation}\]</span>
<p>where <span class="math inline">\(\mathbf{e}^T\)</span>, the transpose of the matrix <span class="math inline">\(\mathbf{e}\)</span>.</p>
<span class="math display">\[\begin{equation}
\label{model_equation}
(\mathbf{Y} - \mathbf{X}\hat{\boldsymbol{\beta}})^T(\mathbf{Y} - \mathbf{X}\hat{\boldsymbol{\beta}}) = (\mathbf{Y}^T\mathbf{Y} - 
\mathbf{Y}^T \mathbf{X}\hat{\boldsymbol{\beta}} - (\hat{\boldsymbol{\beta}}{}^{T}\mathbf{X}^T\mathbf{Y} +
\hat{\boldsymbol{\beta}}{}^{T}\mathbf{X}^T\mathbf{X}
\hat{\boldsymbol{\beta}})
\end{equation}\]</span>
<p>Note that <span class="math inline">\((\mathbf{Y^T}\mathbf{X}\hat{\boldsymbol{\beta}})^T = \hat{\boldsymbol{\beta}}{}^{T}\mathbf{X}^T\mathbf{Y}\)</span>. Since these are both constants (i.e. <span class="math inline">\(1\times 1\)</span> vectors), <span class="math inline">\(\mathbf{Y^T}\mathbf{X}\hat{\boldsymbol{\beta}} = \hat{\boldsymbol{\beta}}{}^{T}\mathbf{X}^T\mathbf{Y}\)</span>. Thus, () becomes</p>
<span class="math display">\[\begin{equation}
\mathbf{Y}^T\mathbf{Y} - 2 \mathbf{X}^T\hat{\boldsymbol{\beta}}{}^{T}\mathbf{Y} + \hat{\boldsymbol{\beta}}{}^{T}\mathbf{X}^T\mathbf{X}
\hat{\boldsymbol{\beta}}
\end{equation}\]</span>
<p>Since we want to find the <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span> that minimizes (), will find the value of <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span> such that the derivative with respect to <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span> is equal to 0.</p>
<span class="math display">\[\begin{equation}
\begin{aligned}
\frac{\partial \mathbf{e}^T\mathbf{e}}{\partial \hat{\boldsymbol{\beta}}} &amp; = \frac{\partial}{\partial \hat{\boldsymbol{\beta}}}(\mathbf{Y}^T\mathbf{Y} - 2 \mathbf{X}^T\hat{\boldsymbol{\beta}}{}^T\mathbf{Y} + \hat{\boldsymbol{\beta}}{}^{T}\mathbf{X}^T\mathbf{X}\hat{\boldsymbol{\beta}}) = 0 \\[10pt]
&amp;\Rightarrow - 2 \mathbf{X}^T\mathbf{Y} + 2 \mathbf{X}^T\mathbf{X}\hat{\boldsymbol{\beta}} = 0 \\[10pt]
&amp; \Rightarrow 2 \mathbf{X}^T\mathbf{Y} = 2 \mathbf{X}^T\mathbf{X}\hat{\boldsymbol{\beta}} \\[10pt]
&amp; \Rightarrow \mathbf{X}^T\mathbf{Y} = \mathbf{X}^T\mathbf{X}\hat{\boldsymbol{\beta}} \\[10pt]
&amp; \Rightarrow (\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\mathbf{Y} = (\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\mathbf{X}\hat{\boldsymbol{\beta}} \\[10pt]
&amp; \Rightarrow (\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\mathbf{Y} = \mathbf{I}\hat{\boldsymbol{\beta}}
\end{aligned}
\end{equation}\]</span>
<p>Thus, the estimate of the model coefficients is <span class="math inline">\(\hat{\boldsymbol{\beta}} = (\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\mathbf{Y}\)</span>.</p>
</div>
<div id="variance-covariance-matrix-of-the-coefficients" class="section level3">
<h3><span class="header-section-number">6.4.4</span> Variance-covariance matrix of the coefficients</h3>
<p>We will use two properties to derive the form of the variance-covarinace matrix of the coefficients:</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(E[\boldsymbol{\epsilon}\boldsymbol{\epsilon}^T] = \sigma^2I\)</span></li>
<li><span class="math inline">\(\hat{\boldsymbol{\beta}} = \boldsymbol{\beta} + (\mathbf{X}^T\mathbf{X})^{-1}\epsilon\)</span></li>
</ol>
First, we will show that <span class="math inline">\(E[\boldsymbol{\epsilon}\boldsymbol{\epsilon}^T] = \sigma^2I\)</span>
<span class="math display">\[\begin{equation}
\label{expected_error}
\begin{aligned}
E[\boldsymbol{\epsilon}\boldsymbol{\epsilon}^T] &amp;= E \begin{bmatrix}\epsilon_1  &amp; \epsilon_2 &amp; \dots &amp; \epsilon_n \end{bmatrix}\begin{bmatrix}\epsilon_1 \\ \epsilon_2 \\ \vdots \\ \epsilon_n \end{bmatrix}  \\[10pt]
&amp; = E \begin{bmatrix} \epsilon_1^2  &amp; \epsilon_1 \epsilon_2 &amp; \dots &amp; \epsilon_1 \epsilon_n \\
\epsilon_2 \epsilon_1 &amp; \epsilon_2^2 &amp; \dots &amp; \epsilon_2 \epsilon_n \\ 
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ 
\epsilon_n \epsilon_1 &amp; \epsilon_n \epsilon_2 &amp; \dots &amp; \epsilon_n^2 
\end{bmatrix} \\[10pt]
&amp; = \begin{bmatrix} E[\epsilon_1^2]  &amp; E[\epsilon_1 \epsilon_2] &amp; \dots &amp; E[\epsilon_1 \epsilon_n] \\
E[\epsilon_2 \epsilon_1] &amp; E[\epsilon_2^2] &amp; \dots &amp; E[\epsilon_2 \epsilon_n] \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ 
E[\epsilon_n \epsilon_1] &amp; E[\epsilon_n \epsilon_2] &amp; \dots &amp; E[\epsilon_n^2]
\end{bmatrix}
\end{aligned}
\end{equation}\]</span>
<p>Recall, the regression assumption that the errors <span class="math inline">\(\epsilon_i&#39;s\)</span> are Normally distributed with mean 0 and variance <span class="math inline">\(\sigma^2\)</span>. Thus, <span class="math inline">\(E(\epsilon_i^2) = Var(\epsilon_i) = \sigma^2\)</span> for all <span class="math inline">\(i\)</span>. Additionally, recall the regression assumption that the errors are uncorrelated, i.e. <span class="math inline">\(E(\epsilon_i \epsilon_j) = Cov(\epsilon_i, \epsilon_j) = 0\)</span> for all <span class="math inline">\(i,j\)</span>. Using these assumptions, we can write () as</p>
<span class="math display">\[\begin{equation}
E[\mathbf{\epsilon}\mathbf{\epsilon}^T]  = \begin{bmatrix} \sigma^2  &amp; 0 &amp; \dots &amp; 0 \\
0 &amp; \sigma^2  &amp; \dots &amp; 0 \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \dots &amp; \sigma^2
\end{bmatrix} = \sigma^2 \mathbf{I}
\end{equation}\]</span>
<p>where <span class="math inline">\(\mathbf{I}\)</span> is the <span class="math inline">\(n \times n\)</span> identity matrix.</p>
<p>Next, we show that <span class="math inline">\(\hat{\boldsymbol{\beta}} = \boldsymbol{\beta} + (\mathbf{X}^T\mathbf{X})^{-1}\epsilon\)</span>.</p>
<p>Recall that the <span class="math inline">\(\hat{\boldsymbol{\beta}} = (\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\mathbf{Y}\)</span> and <span class="math inline">\(\mathbf{Y} = \mathbf{X}\mathbf{\beta} + \mathbf{\epsilon}\)</span>. Then,</p>
<span class="math display">\[\begin{equation}
\begin{aligned}
\hat{\boldsymbol{\beta}} &amp;= (\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\mathbf{Y} \\[10pt]
&amp;= (\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T(\mathbf{X}\boldsymbol{\beta} + \boldsymbol{\epsilon}) \\[10pt]
&amp;= \boldsymbol{\beta} + (\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T \mathbf{\epsilon} \\
\end{aligned}
\end{equation}\]</span>
<p>Using these two properties, we derive the form of the variance-covariance matrix for the coefficients. Note that the covariance matrix is <span class="math inline">\(E[(\hat{\boldsymbol{\beta}} - \boldsymbol{\beta})(\hat{\boldsymbol{\beta}} - \boldsymbol{\beta})^T]\)</span></p>
<span class="math display">\[\begin{equation}
\begin{aligned}
E[(\hat{\boldsymbol{\beta}} - \boldsymbol{\beta})(\hat{\boldsymbol{\beta}} - \boldsymbol{\beta})^T] &amp;= E[(\boldsymbol{\beta} + (\mathbf{X}^T\mathbf{X})^{-1} \mathbf{X}^T \boldsymbol{\epsilon} - \boldsymbol{\beta})(\boldsymbol{\beta} + (\mathbf{X}^T\mathbf{X})^{-1} \mathbf{X}^T \boldsymbol{\epsilon} - \boldsymbol{\beta})^T]\\[10pt]
&amp; = E[(\mathbf{X}^T\mathbf{X})^{-1} \mathbf{X}^T \boldsymbol{\epsilon}\boldsymbol{\epsilon}^T\mathbf{X}(\mathbf{X}^T\mathbf{X})^{-1}] \\[10pt]
&amp; = (\mathbf{X}^T\mathbf{X})^{-1} \mathbf{X}^T E[\boldsymbol{\epsilon}\boldsymbol{\epsilon}^T]\mathbf{X}(\mathbf{X}^T\mathbf{X})^{-1}\\[10pt]
&amp; = (\mathbf{X}^T\mathbf{X})^{-1} \mathbf{X}^T (\sigma^2\mathbf{I})\mathbf{X}(\mathbf{X}^T\mathbf{X})^{-1}\\
&amp;= \sigma^2\mathbf{I}(\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\mathbf{X}(\mathbf{X}^T\mathbf{X})^{-1}\\[10pt]
&amp; = \sigma^2\mathbf{I}(\mathbf{X}^T\mathbf{X})^{-1}\\[10pt]
&amp;  = \sigma^2(\mathbf{X}^T\mathbf{X})^{-1} \\
\end{aligned}
\end{equation}\]</span>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="6-3-analyzing-wages.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="6-5-log-transformations-in-linear-regression.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": ["intro-regression.pdf", "intro-regression.epub"],
"toc": {
"collapse": "section",
"toc_depth": 1,
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
